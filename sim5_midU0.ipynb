{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-27T23:38:15.041652Z",
     "start_time": "2024-11-27T23:38:15.038282Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from scipy.stats import pearsonr\n",
    "from IPython.display import display, Math, Markdown\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0. Introduction\n",
   "id": "1bceec036e2735e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Simulations in this document are for the approach outlined in draft 3.2. We generate data under settings such that sequential conditional exchangeability assumption holds with full set of covariates. We compute the population quantity of mean potential outcome under treatment path $\\bar{A} = \\bar{1}$ (1), the population AIPW $\\psi$ based on (8), the incorrect population AIPW $\\psi^*$ based on (11), their difference $\\psi^*-\\psi$ as listed (12). Moreover, we compute the basic ovb based on equation (13), updated ovb based on equation (26),  the ovb bound based on (14) together with (18) (19) (20), and the ovb bound based on (14), (18) (19) (20), and corollary 1.\n",
    "\n",
    "## 1. Data Generating \n",
    "\n",
    "### 1.1 Description\n",
    "\n",
    "\\begin{align*}\n",
    "U_0 &\\sim \\mathcal{N}(0, \\sigma_{U_0}^2), \\\\[1em]\n",
    "L_0 &= \\beta_{L_0|U_0} U_0 + \\epsilon_{L_0}, \\quad \\epsilon_{L_0} \\sim \\mathcal{N}(0, \\sigma_{L_0}^2), \\\\[1em]\n",
    "P(A_0 = 1 \\mid L_0 = \\ell_0, U_0 = u_0) &= \\left[1 + \\exp\\{- (\\beta_{A_0|L_0} \\ell_0 + \\beta_{A_0|U_0} u_0)\\}\\right]^{-1}, \\\\[1em]\n",
    "L_1 &= \\beta_{L_1|L_0} L_0 + \\beta_{L_1|A_0} A_0 + \\beta_{L_1|U_0} U_0 + \\epsilon_{L_1}, \\quad \\epsilon_{L_1} \\sim \\mathcal{N}(0, \\sigma_{L_1}^2), \\\\[1em]\n",
    "P(A_1 = 1 \\mid L_0 = \\ell_0, L_1 = \\ell_1, A_0 = a_0, U_0 = u_0) &= \\left[1 + \\exp\\{- (\\beta_{A_1|L_1} \\ell_1 + \\beta_{A_1|A_0} a_0 + \\beta_{A_1|L_0} \\ell_0 + \\beta_{A_1|U_0} u_0)\\}\\right]^{-1}, \\\\[1em]\n",
    "Y &= \\gamma_{Y|L_0} L_0 + \\gamma_{Y|L_1} L_1 + \\gamma_{Y|A_0} A_0 + \\gamma_{Y|A_1} A_1 + \\gamma_{Y|U_0} U_0 + \\epsilon_Y, \\quad \\epsilon_Y \\sim \\mathcal{N}(0, \\sigma_Y^2).\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "\\beta_{L0} &= (\\beta_{L_0|U_0} ) = 0.5, \\\\\n",
    "\\beta_{A_0} &= (\\beta_{A_0|L_0}, \\beta_{A_0|U_0}) = (0.5, 0.8),\\\\\n",
    "\\beta_{L_1} &= (\\beta_{L_1|L_0}, \\beta_{L_1|A_0}, \\beta_{L_1|U_0}) = (0.6, 0.4, 0.4), \\\\\n",
    "\\beta_{A_1} &= (\\beta_{A_1|L_1}, \\beta_{A_1|A_0}, \\beta_{A_1|L_0}, \\beta_{A_1|U_0}) = (0.4, 0.2, 0.3, 0.5), \\\\\n",
    "\\gamma_{Y} &= (\\gamma_{Y|L_0}, \\gamma_{Y|L_1} L_1, \\gamma_{Y|A_0} A_0,  \\gamma_{Y|A_1} , \\gamma_{Y|U_0} ) = (1.2, 0.8, 0.5, 0.7, 0.8),\\\\\n",
    "\\sigma_{U_0} &= 1,\\\\\n",
    "\\sigma_{L_0} &= 1,\\\\\n",
    "\\sigma_{L_1} &= 1,\\\\\n",
    "\\sigma_Y &= 1.\n",
    "\\end{align*}"
   ],
   "id": "a68ce594ac9e4890"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T23:39:15.968731Z",
     "start_time": "2024-11-27T23:39:12.014270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setting seed\n",
    "np.random.seed(43)\n",
    "\n",
    "# Large sample size\n",
    "n = 20000000\n",
    "\n",
    "# Define parameters for the data-generating process\n",
    "params = {\n",
    "    \"U0_std\": 1.0,          # Standard deviation for U_0\n",
    "    \"L0_U0_coeff\": 0.5,     # Reduced coefficient for U_0 in L_0 <--\n",
    "    \"L0_noise_std\": 1.0,    # Standard deviation for noise in L_0\n",
    "    \"A0_L0_coeff\": 0.5,     # Coefficient for L_0 in A_0\n",
    "    \"A0_U0_coeff\": 0.8,     # Reduced coefficient for U_0 in A_0 <--\n",
    "    \"L1_L0_coeff\": 0.6,     # Coefficient for L_0 in L_1\n",
    "    \"L1_A0_coeff\": 0.4,     # Coefficient for A_0 in L_1\n",
    "    \"L1_U0_coeff\": 0.4,     # Reduced coefficient for U_0 in L_1 <--\n",
    "    \"L1_noise_std\": 1.0,    # Standard deviation for noise in L_1\n",
    "    \"A1_L1_coeff\": 0.4,     # Coefficient for L_1 in A_1\n",
    "    \"A1_A0_coeff\": 0.2,     # Coefficient for A_0 in A_1\n",
    "    \"A1_L0_coeff\": 0.3,     # Coefficient for L_0 in A_1\n",
    "    \"A1_U0_coeff\": 0.5,     # Reduced coefficient for U_0 in A_1 <--\n",
    "    \"Y_L0_coeff\": 1.2,      # Coefficient for L_0 in Y\n",
    "    \"Y_L1_coeff\": 0.8,      # Coefficient for L_1 in Y\n",
    "    \"Y_A0_coeff\": 0.5,      # Coefficient for A_0 in Y\n",
    "    \"Y_A1_coeff\": 0.7,      # Coefficient for A_1 in Y\n",
    "    \"Y_U0_coeff\": 0.8,      # Reduced coefficient for U_0 in Y <--\n",
    "    \"Y_noise_std\": 1.0      # Standard deviation for noise in Y\n",
    "}\n",
    "\n",
    "# Step 1: Generate U0 (baseline unobserved covariates)\n",
    "U_0 = np.random.normal(0, params[\"U0_std\"], n)  # U_0 ~ Normal(0, std)\n",
    "\n",
    "# Step 2: Generate L0 (baseline observed covariates) as a function of U0\n",
    "L_0 = params[\"L0_U0_coeff\"] * U_0 + np.random.normal(0, params[\"L0_noise_std\"], n)\n",
    "\n",
    "# Step 3: Generate A0 (treatment at time 0) based on L0 and U0\n",
    "p_A0 = 1 / (1 + np.exp(-(params[\"A0_L0_coeff\"] * L_0 + params[\"A0_U0_coeff\"] * U_0)))\n",
    "A_0 = np.random.binomial(1, p_A0, n)\n",
    "\n",
    "# Step 4: Generate L1 (covariates at time 1) based on L0, U0, and A0\n",
    "L_1 = (params[\"L1_L0_coeff\"] * L_0 +\n",
    "       params[\"L1_A0_coeff\"] * A_0 +\n",
    "       params[\"L1_U0_coeff\"] * U_0 +\n",
    "       np.random.normal(0, params[\"L1_noise_std\"], n))\n",
    "\n",
    "# Step 5: Generate A1 (treatment at time 1) based on L0, U0, L1, and A0\n",
    "p_A1 = 1 / (1 + np.exp(-(params[\"A1_L1_coeff\"] * L_1 +\n",
    "                        params[\"A1_A0_coeff\"] * A_0 +\n",
    "                        params[\"A1_L0_coeff\"] * L_0 +\n",
    "                        params[\"A1_U0_coeff\"] * U_0)))\n",
    "A_1 = np.random.binomial(1, p_A1, n)\n",
    "\n",
    "# Step 6: Generate observed outcome Y based on L0, U0, A0, A1, and L1\n",
    "Y = (params[\"Y_L0_coeff\"] * L_0 +\n",
    "     params[\"Y_L1_coeff\"] * L_1 +\n",
    "     params[\"Y_A0_coeff\"] * A_0 +\n",
    "     params[\"Y_A1_coeff\"] * A_1 +\n",
    "     params[\"Y_U0_coeff\"] * U_0 +\n",
    "     np.random.normal(0, params[\"Y_noise_std\"], n))\n"
   ],
   "id": "447cba8af1875011",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T23:39:19.969974Z",
     "start_time": "2024-11-27T23:39:18.843416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 7: Regenerate L1 under the intervention A0=1\n",
    "# L1_bar1: covariates at time 1 assuming A0=1\n",
    "L1_bar1 = (params[\"L1_L0_coeff\"] * L_0 +\n",
    "           params[\"L1_A0_coeff\"] * 1 +  # Intervention A0=1\n",
    "           params[\"L1_U0_coeff\"] * U_0 +\n",
    "           np.random.normal(0, params[\"L1_noise_std\"], n))\n",
    "\n",
    "# Y_bar1: potential outcome under treatment path (A0=1, A1=1)\n",
    "Y_bar1 = (params[\"Y_L0_coeff\"] * L_0 +\n",
    "          params[\"Y_L1_coeff\"] * L1_bar1 +\n",
    "          params[\"Y_A0_coeff\"] * 1 +  # Intervention A0=1\n",
    "          params[\"Y_A1_coeff\"] * 1 +  # Intervention A1=1\n",
    "          params[\"Y_U0_coeff\"] * U_0 +\n",
    "          np.random.normal(0, params[\"Y_noise_std\"], n))"
   ],
   "id": "71d2c770e7558b8f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T23:39:24.117259Z",
     "start_time": "2024-11-27T23:39:21.937170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Combine data into a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    \"L_0\": L_0,\n",
    "    \"U_0\": U_0,\n",
    "    \"A_0\": A_0,\n",
    "    \"L_1\": L_1,\n",
    "    \"A_1\": A_1,\n",
    "    \"Y\": Y,\n",
    "    \"L1_bar1\": L1_bar1,\n",
    "    \"Y_bar1\": Y_bar1\n",
    "})\n",
    "\n",
    "print(data.shape)"
   ],
   "id": "eeadede230a51af0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000000, 8)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.2 Check sequential conditional exchangeability holds with full set of covariates via ROC AUC\n",
   "id": "5c5c8ea8235e4cfb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T21:42:16.921018Z",
     "start_time": "2024-11-27T21:42:16.915595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Exploratory Checks Using ROC AUC via prediction model XGBoost \n",
    "def roc_aud_conditional_independence_test(X, y, additional_var=None):\n",
    "    \"\"\"Test conditional independence using XGBoost and ROC AUC.\"\"\"\n",
    "    model = XGBClassifier(eval_metric=\"logloss\")\n",
    "    model.fit(X, y)\n",
    "    baseline_roc_auc = roc_auc_score(y, model.predict_proba(X)[:, 1])\n",
    "\n",
    "    if additional_var is not None:\n",
    "        X_with_additional = np.column_stack((X, additional_var))\n",
    "        model_with_additional = XGBClassifier(eval_metric=\"logloss\")\n",
    "        model_with_additional.fit(X_with_additional, y)\n",
    "        additional_roc_auc = roc_auc_score(y, model_with_additional.predict_proba(X_with_additional)[:, 1])\n",
    "        return baseline_roc_auc, additional_roc_auc\n",
    "    else:\n",
    "        return baseline_roc_auc\n",
    "\n"
   ],
   "id": "cb43aba7094e223c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T21:42:23.021391Z",
     "start_time": "2024-11-27T21:42:20.225596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test 1: Y^{\\bar{1}} ⫫ A0 | L0, U0\n",
    "X = data[['L_0', 'U_0']].values\n",
    "y = data['A_0'].values\n",
    "baseline_auc, auc_with_y = roc_aud_conditional_independence_test(X, y, data['Y_bar1'].values)\n",
    "print(f\"Test 1 (with U0): Baseline AUC={baseline_auc}, AUC with Y_bar1={auc_with_y}\")\n"
   ],
   "id": "1b03fe17963f4a60",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <bound method DataIter._next_wrapper of <xgboost.data.SingleBatchInternalIter object at 0x1043bceb0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/ucsd1/lib/python3.9/site-packages/xgboost/core.py\", line 582, in _next_wrapper\n",
      "    def _next_wrapper(self, this: None) -> int:  # pylint: disable=unused-argument\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[13:42:22] /Users/runner/work/xgboost/xgboost/src/common/quantile.h:770: Check failed: count <= total_entries (20000000 vs. 0) : \nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x000000014a638454 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n  [bt] (1) 2   libxgboost.dylib                    0x000000014a737c04 std::__1::vector<unsigned int, std::__1::allocator<unsigned int>> xgboost::common::LoadBalance<xgboost::data::ArrayAdapterBatch, xgboost::data::IsValidFunctor&>(xgboost::data::ArrayAdapterBatch const&, unsigned long, unsigned int, unsigned long, xgboost::data::IsValidFunctor&) + 432\n  [bt] (2) 3   libxgboost.dylib                    0x000000014a737764 void xgboost::common::SketchContainerImpl<xgboost::common::WQuantileSketch<float, float>>::PushRowPageImpl<xgboost::data::ArrayAdapterBatch, xgboost::data::IsValidFunctor>(xgboost::data::ArrayAdapterBatch const&, unsigned long, xgboost::common::OptionalWeights, unsigned long, unsigned long, bool, xgboost::data::IsValidFunctor) + 152\n  [bt] (3) 4   libxgboost.dylib                    0x000000014a73701c void xgboost::common::HostSketchContainer::PushAdapterBatch<xgboost::data::ArrayAdapterBatch>(xgboost::data::ArrayAdapterBatch const&, unsigned long, xgboost::MetaInfo const&, float) + 248\n  [bt] (4) 5   libxgboost.dylib                    0x000000014a7ca0f4 xgboost::data::IterativeDMatrix::InitFromCPU(xgboost::Context const*, xgboost::BatchParam const&, void*, float, std::__1::shared_ptr<xgboost::DMatrix>) + 8024\n  [bt] (5) 6   libxgboost.dylib                    0x000000014a7c7db0 xgboost::data::IterativeDMatrix::IterativeDMatrix(void*, void*, std::__1::shared_ptr<xgboost::DMatrix>, void (*)(void*), int (*)(void*), float, int, int) + 840\n  [bt] (6) 7   libxgboost.dylib                    0x000000014a7842d8 xgboost::DMatrix* xgboost::DMatrix::Create<void*, void*, void (void*), int (void*)>(void*, void*, std::__1::shared_ptr<xgboost::DMatrix>, void (*)(void*), int (*)(void*), float, int, int) + 140\n  [bt] (7) 8   libxgboost.dylib                    0x000000014a641628 XGQuantileDMatrixCreateFromCallback + 496\n  [bt] (8) 9   libffi.8.dylib                      0x000000010151004c ffi_call_SYSV + 76\n\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mXGBoostError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m X \u001B[38;5;241m=\u001B[39m data[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mL_0\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mU_0\u001B[39m\u001B[38;5;124m'\u001B[39m]]\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m      3\u001B[0m y \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mA_0\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues\n\u001B[0;32m----> 4\u001B[0m baseline_auc, auc_with_y \u001B[38;5;241m=\u001B[39m \u001B[43mroc_aud_conditional_independence_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mY_bar1\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTest 1 (with U0): Baseline AUC=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbaseline_auc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, AUC with Y_bar1=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mauc_with_y\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[6], line 5\u001B[0m, in \u001B[0;36mroc_aud_conditional_independence_test\u001B[0;34m(X, y, additional_var)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Test conditional independence using XGBoost and ROC AUC.\"\"\"\u001B[39;00m\n\u001B[1;32m      4\u001B[0m model \u001B[38;5;241m=\u001B[39m XGBClassifier(eval_metric\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogloss\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m baseline_roc_auc \u001B[38;5;241m=\u001B[39m roc_auc_score(y, model\u001B[38;5;241m.\u001B[39mpredict_proba(X)[:, \u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m additional_var \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ucsd1/lib/python3.9/site-packages/xgboost/core.py:726\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    724\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[1;32m    725\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[0;32m--> 726\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ucsd1/lib/python3.9/site-packages/xgboost/sklearn.py:1512\u001B[0m, in \u001B[0;36mXGBClassifier.fit\u001B[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_class\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_\n\u001B[1;32m   1511\u001B[0m model, metric, params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_configure_fit(xgb_model, params)\n\u001B[0;32m-> 1512\u001B[0m train_dmatrix, evals \u001B[38;5;241m=\u001B[39m \u001B[43m_wrap_evaluation_matrices\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1513\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmissing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmissing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1514\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1515\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1516\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroup\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1517\u001B[0m \u001B[43m    \u001B[49m\u001B[43mqid\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1518\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1519\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbase_margin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbase_margin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1520\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeature_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_weights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1521\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight_eval_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight_eval_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1523\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbase_margin_eval_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbase_margin_eval_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1524\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_group\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1525\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_qid\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1526\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_dmatrix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_dmatrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1527\u001B[0m \u001B[43m    \u001B[49m\u001B[43menable_categorical\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menable_categorical\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1528\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeature_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m train(\n\u001B[1;32m   1532\u001B[0m     params,\n\u001B[1;32m   1533\u001B[0m     train_dmatrix,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1542\u001B[0m     callbacks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks,\n\u001B[1;32m   1543\u001B[0m )\n\u001B[1;32m   1545\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective):\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ucsd1/lib/python3.9/site-packages/xgboost/sklearn.py:596\u001B[0m, in \u001B[0;36m_wrap_evaluation_matrices\u001B[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001B[0m\n\u001B[1;32m    576\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_wrap_evaluation_matrices\u001B[39m(\n\u001B[1;32m    577\u001B[0m     missing: \u001B[38;5;28mfloat\u001B[39m,\n\u001B[1;32m    578\u001B[0m     X: Any,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    592\u001B[0m     feature_types: Optional[FeatureTypes],\n\u001B[1;32m    593\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Any, List[Tuple[Any, \u001B[38;5;28mstr\u001B[39m]]]:\n\u001B[1;32m    594\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001B[39;00m\n\u001B[1;32m    595\u001B[0m \u001B[38;5;124;03m    way.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 596\u001B[0m     train_dmatrix \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_dmatrix\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    597\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    598\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    599\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgroup\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    600\u001B[0m \u001B[43m        \u001B[49m\u001B[43mqid\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mqid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    601\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    602\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbase_margin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbase_margin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    603\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfeature_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_weights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    604\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmissing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmissing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    605\u001B[0m \u001B[43m        \u001B[49m\u001B[43menable_categorical\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menable_categorical\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    606\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfeature_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    607\u001B[0m \u001B[43m        \u001B[49m\u001B[43mref\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    608\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    610\u001B[0m     n_validation \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m eval_set \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(eval_set)\n\u001B[1;32m    612\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalidate_or_none\u001B[39m(meta: Optional[Sequence], name: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Sequence:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ucsd1/lib/python3.9/site-packages/xgboost/sklearn.py:1003\u001B[0m, in \u001B[0;36mXGBModel._create_dmatrix\u001B[0;34m(self, ref, **kwargs)\u001B[0m\n\u001B[1;32m   1001\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _can_use_qdm(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtree_method) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbooster \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgblinear\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1002\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1003\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mQuantileDMatrix\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1004\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mref\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mref\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnthread\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_bin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_bin\u001B[49m\n\u001B[1;32m   1005\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1006\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:  \u001B[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001B[39;00m\n\u001B[1;32m   1007\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ucsd1/lib/python3.9/site-packages/xgboost/core.py:726\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    724\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[1;32m    725\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[0;32m--> 726\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ucsd1/lib/python3.9/site-packages/xgboost/core.py:1573\u001B[0m, in \u001B[0;36mQuantileDMatrix.__init__\u001B[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001B[0m\n\u001B[1;32m   1553\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(\n\u001B[1;32m   1554\u001B[0m         info \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1555\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m info \u001B[38;5;129;01min\u001B[39;00m (\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1566\u001B[0m         )\n\u001B[1;32m   1567\u001B[0m     ):\n\u001B[1;32m   1568\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1569\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf data iterator is used as input, data like label should be \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1570\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspecified as batch argument.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1571\u001B[0m         )\n\u001B[0;32m-> 1573\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1574\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1575\u001B[0m \u001B[43m    \u001B[49m\u001B[43mref\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mref\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1576\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlabel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1577\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1578\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbase_margin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbase_margin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1579\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroup\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1580\u001B[0m \u001B[43m    \u001B[49m\u001B[43mqid\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mqid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1581\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlabel_lower_bound\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabel_lower_bound\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1582\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlabel_upper_bound\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabel_upper_bound\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1583\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeature_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_weights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1584\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1585\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeature_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1586\u001B[0m \u001B[43m    \u001B[49m\u001B[43menable_categorical\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menable_categorical\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1587\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ucsd1/lib/python3.9/site-packages/xgboost/core.py:1634\u001B[0m, in \u001B[0;36mQuantileDMatrix._init\u001B[0;34m(self, data, ref, enable_categorical, **meta)\u001B[0m\n\u001B[1;32m   1632\u001B[0m it\u001B[38;5;241m.\u001B[39mreraise()\n\u001B[1;32m   1633\u001B[0m \u001B[38;5;66;03m# delay check_call to throw intermediate exception first\u001B[39;00m\n\u001B[0;32m-> 1634\u001B[0m \u001B[43m_check_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mret\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1635\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle \u001B[38;5;241m=\u001B[39m handle\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ucsd1/lib/python3.9/site-packages/xgboost/core.py:284\u001B[0m, in \u001B[0;36m_check_call\u001B[0;34m(ret)\u001B[0m\n\u001B[1;32m    273\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Check the return value of C API call\u001B[39;00m\n\u001B[1;32m    274\u001B[0m \n\u001B[1;32m    275\u001B[0m \u001B[38;5;124;03mThis function will raise exception when error occurs.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;124;03m    return value from API calls\u001B[39;00m\n\u001B[1;32m    282\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    283\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 284\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m XGBoostError(py_str(_LIB\u001B[38;5;241m.\u001B[39mXGBGetLastError()))\n",
      "\u001B[0;31mXGBoostError\u001B[0m: [13:42:22] /Users/runner/work/xgboost/xgboost/src/common/quantile.h:770: Check failed: count <= total_entries (20000000 vs. 0) : \nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x000000014a638454 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n  [bt] (1) 2   libxgboost.dylib                    0x000000014a737c04 std::__1::vector<unsigned int, std::__1::allocator<unsigned int>> xgboost::common::LoadBalance<xgboost::data::ArrayAdapterBatch, xgboost::data::IsValidFunctor&>(xgboost::data::ArrayAdapterBatch const&, unsigned long, unsigned int, unsigned long, xgboost::data::IsValidFunctor&) + 432\n  [bt] (2) 3   libxgboost.dylib                    0x000000014a737764 void xgboost::common::SketchContainerImpl<xgboost::common::WQuantileSketch<float, float>>::PushRowPageImpl<xgboost::data::ArrayAdapterBatch, xgboost::data::IsValidFunctor>(xgboost::data::ArrayAdapterBatch const&, unsigned long, xgboost::common::OptionalWeights, unsigned long, unsigned long, bool, xgboost::data::IsValidFunctor) + 152\n  [bt] (3) 4   libxgboost.dylib                    0x000000014a73701c void xgboost::common::HostSketchContainer::PushAdapterBatch<xgboost::data::ArrayAdapterBatch>(xgboost::data::ArrayAdapterBatch const&, unsigned long, xgboost::MetaInfo const&, float) + 248\n  [bt] (4) 5   libxgboost.dylib                    0x000000014a7ca0f4 xgboost::data::IterativeDMatrix::InitFromCPU(xgboost::Context const*, xgboost::BatchParam const&, void*, float, std::__1::shared_ptr<xgboost::DMatrix>) + 8024\n  [bt] (5) 6   libxgboost.dylib                    0x000000014a7c7db0 xgboost::data::IterativeDMatrix::IterativeDMatrix(void*, void*, std::__1::shared_ptr<xgboost::DMatrix>, void (*)(void*), int (*)(void*), float, int, int) + 840\n  [bt] (6) 7   libxgboost.dylib                    0x000000014a7842d8 xgboost::DMatrix* xgboost::DMatrix::Create<void*, void*, void (void*), int (void*)>(void*, void*, std::__1::shared_ptr<xgboost::DMatrix>, void (*)(void*), int (*)(void*), float, int, int) + 140\n  [bt] (7) 8   libxgboost.dylib                    0x000000014a641628 XGQuantileDMatrixCreateFromCallback + 496\n  [bt] (8) 9   libffi.8.dylib                      0x000000010151004c ffi_call_SYSV + 76\n\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Test 2: Y^{\\bar{1}} ⫫ A0 | L0\n",
    "X = data[['L_0']].values\n",
    "y = data['A_0'].values\n",
    "baseline_auc, auc_with_y = roc_aud_conditional_independence_test(X, y, data['Y_bar1'].values)\n",
    "print(f\"Test 2 (without U0): Baseline AUC={baseline_auc}, AUC with Y_bar1={auc_with_y}\")\n"
   ],
   "id": "653e0fc9ea2de068"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.3 Check sequential conditional exchangeability is violated with only observed set of covaraites via ROC AUC \n",
   "id": "c82cb46cec3cc205"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Test 3: Y^{\\bar{1}} ⫫ A1 | A0, L0, U0, L1\n",
    "X = data[['A_0', 'L_0', 'U_0', 'L_1']].values\n",
    "y = data['A_1'].values\n",
    "baseline_auc, auc_with_y = roc_aud_conditional_independence_test(X, y, data['Y_bar1'].values)\n",
    "print(f\"Test 3 (with U0): Baseline AUC={baseline_auc}, AUC with Y_bar1={auc_with_y}\")\n"
   ],
   "id": "a252e3a8be9d88d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Test 4: Y^{\\bar{1}} ⫫ A1 | A0, L0, L_1\n",
    "X = data[['A_0', 'L_0', 'L_1']].values\n",
    "y = data['A_1'].values\n",
    "baseline_auc, auc_with_y = roc_aud_conditional_independence_test(X, y, data['Y_bar1'].values)\n",
    "print(f\"Test 4 (without U0): Baseline AUC={baseline_auc}, AUC with Y_bar1={auc_with_y}\")\n"
   ],
   "id": "14413ad492a277a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Compute population quantities\n",
   "id": "772c931b6b5a3010"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T23:40:02.623585Z",
     "start_time": "2024-11-27T23:39:33.508095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Restrict to certain subset, follow the math expression\n",
    "\n",
    "# Split the data into training and prediction sets\n",
    "train_data = data[:10000000]   # First 1000 rows for training\n",
    "predict_data = data[10000000:].copy() # Last 1000 rows for prediction\n",
    "\n",
    "# # Step 1: estimate b1_true and attach to predict_data\n",
    "# train_subset_a0a1 = train_data[(train_data['A_0'] == 1) & (train_data['A_1'] == 1)]\n",
    "# X_train1 = train_subset_a0a1[['L_0', 'L_1', 'U_0']]\n",
    "# Y_train1 = train_subset_a0a1['Y']\n",
    "# model1 = LinearRegression()\n",
    "# model1.fit(X_train1, Y_train1)\n",
    "# X_predict1 = predict_data[['L_0', 'L_1', 'U_0']]\n",
    "# predict_data = predict_data.copy()  # Create an explicit copy to avoid SettingWithCopyWarning\n",
    "# predict_data.loc[:, 'b1_true'] = model1.predict(X_predict1)  # Use .loc for explicit assignment\n",
    "\n",
    "# Step 1: get b1_true from the data generating process directly\n",
    "predict_data['b1_true'] = (params[\"Y_L0_coeff\"] * predict_data['L_0'] +\n",
    "                           params[\"Y_L1_coeff\"] * predict_data['L_1'] +\n",
    "                           params[\"Y_A0_coeff\"] * 1 +  # Set A0=1\n",
    "                           params[\"Y_A1_coeff\"] * 1 +  # Set A1=1\n",
    "                           params[\"Y_U0_coeff\"] * predict_data['U_0'])\n",
    "\n",
    "# Step 2: estimate b1_short and attach to predict_data\n",
    "train_subset_a0a1 = train_data[(train_data['A_0'] == 1) & (train_data['A_1'] == 1)]\n",
    "X_train2 = train_subset_a0a1[['L_0', 'L_1']]\n",
    "Y_train2 = train_subset_a0a1['Y']\n",
    "model2 = LinearRegression()\n",
    "model2.fit(X_train2, Y_train2)\n",
    "X_predict2 = predict_data[['L_0', 'L_1']]\n",
    "# No additional .copy() needed here as we already created one in Step 1\n",
    "predict_data.loc[:, 'b1_short'] = model2.predict(X_predict2)  # Use .loc for consistency\n",
    "\n",
    "# # Step 5: estimate pi1_true\n",
    "# train_subset_a0 = train_data[train_data['A_0'] == 1]\n",
    "# X_train5 = train_subset_a0[['L_0', 'L_1', 'U_0']]\n",
    "# Y_train5 = train_subset_a0['A_1']\n",
    "# model5 = LogisticRegression()\n",
    "# model5.fit(X_train5, Y_train5)\n",
    "# X_predict5 = predict_data[['L_0', 'L_1', 'U_0']]\n",
    "# predict_data.loc[:, 'pi1_true'] = model5.predict_proba(X_predict5)[:, 1]\n",
    "\n",
    "# Step 5: get pi1_true from the data generating process directly\n",
    "predict_data.loc[:, 'pi1_true'] = 1 / (1 + np.exp(-(params[\"A1_L1_coeff\"] * predict_data['L_1'] +\n",
    "                                            params[\"A1_A0_coeff\"] * 1 +  # Set A0 = 1\n",
    "                                            params[\"A1_L0_coeff\"] * predict_data['L_0'] +\n",
    "                                            params[\"A1_U0_coeff\"] * predict_data['U_0'])))\n",
    "\n",
    "# Step 6: estimate pi1_short\n",
    "train_subset_a0 = train_data[train_data['A_0'] == 1]\n",
    "X_train6 = train_subset_a0[['L_0', 'L_1']]\n",
    "Y_train6 = train_subset_a0['A_1']\n",
    "# model6 = LogisticRegression()\n",
    "# model6 = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=43)  # Nonparametric model\n",
    "model6 = XGBClassifier(\n",
    "    n_estimators=100,     # Number of trees\n",
    "    max_depth=5,          # Maximum depth of a tree\n",
    "    learning_rate=0.1,    # Learning rate (eta)\n",
    "    subsample=0.8,        # Subsample ratio of training data\n",
    "    colsample_bytree=0.8, # Subsample ratio of columns when constructing each tree\n",
    "    random_state=43       # Random seed for reproducibility\n",
    ")\n",
    "model6.fit(X_train6, Y_train6)\n",
    "X_predict6 = predict_data[['L_0', 'L_1']]\n",
    "predict_data.loc[:, 'pi1_short'] = model6.predict_proba(X_predict6)[:, 1]\n",
    "\n",
    "# # Step 7: estimate pi0_true\n",
    "# X_train7 = train_data[['L_0', 'U_0']]\n",
    "# Y_train7 = train_data['A_0']\n",
    "# model7 = LogisticRegression()\n",
    "# model7.fit(X_train7, Y_train7)\n",
    "# X_predict7 = predict_data[['L_0', 'U_0']]\n",
    "# predict_data.loc[:, 'pi0_true'] = model7.predict_proba(X_predict7)[:, 1]\n",
    "\n",
    "# Step 7: get pi0_true from the data generating process directly\n",
    "predict_data.loc[:, 'pi0_true'] = 1 / (1 + np.exp(-(params[\"A0_L0_coeff\"] * predict_data['L_0'] +\n",
    "                                            params[\"A0_U0_coeff\"] * predict_data['U_0'])))\n",
    "\n",
    "# Step 8: estimate pi0_short\n",
    "X_train8 = train_data[['L_0']]\n",
    "Y_train8 = train_data['A_0']\n",
    "# model8 = LogisticRegression()\n",
    "# model8 = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=43)  # Nonparametric model\n",
    "model8 = XGBClassifier(\n",
    "    n_estimators=100,     # Number of trees\n",
    "    max_depth=5,          # Maximum depth of a tree\n",
    "    learning_rate=0.1,    # Learning rate (eta)\n",
    "    subsample=0.8,        # Subsample ratio of training data\n",
    "    colsample_bytree=0.8, # Subsample ratio of columns when constructing each tree\n",
    "    random_state=43       # Random seed for reproducibility\n",
    ")\n",
    "model8.fit(X_train8, Y_train8)\n",
    "X_predict8 = predict_data[['L_0']]\n",
    "predict_data.loc[:, 'pi0_short'] = model8.predict_proba(X_predict8)[:, 1]\n",
    "\n",
    "# Step 3: estimate b0_true\n",
    "predict_train, predict_test = train_test_split(predict_data, test_size=0.5, random_state=42)\n",
    "predict_test = predict_test.copy()\n",
    "predict_train_subset = predict_train[predict_train['A_0'] == 1].copy()\n",
    "X_train3 = predict_train_subset[['L_0', 'U_0']]\n",
    "Y_train3 = predict_train_subset['b1_true']\n",
    "model3 = LinearRegression()\n",
    "model3.fit(X_train3, Y_train3)\n",
    "X_test3 = predict_test[['L_0', 'U_0']]\n",
    "predict_test.loc[:, 'b0_true'] = model3.predict(X_test3)  \n",
    "\n",
    "# Step 10: estimate ite_b1b0_short_true\n",
    "X_train10 = predict_train_subset[['L_0', 'U_0']]\n",
    "Y_train10 = predict_train_subset['b1_short']\n",
    "model10 = LinearRegression()\n",
    "model10.fit(X_train10, Y_train10)\n",
    "X_test10 = predict_test[['L_0', 'U_0']]\n",
    "predict_test.loc[:, 'ite_b1b0_short_true'] = model10.predict(X_test10)  \n",
    "\n",
    "# Step 4: estimate b0_short\n",
    "X_train4 = predict_train_subset[['L_0']]\n",
    "Y_train4 = predict_train_subset['b1_short']\n",
    "model4 = LinearRegression()\n",
    "model4.fit(X_train4, Y_train4)\n",
    "X_test4 = predict_test[['L_0']]\n",
    "predict_test.loc[:, 'b0_short'] = model4.predict(X_test4)"
   ],
   "id": "d93300bfbea9a6de",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T23:40:16.947032Z",
     "start_time": "2024-11-27T23:40:16.766908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute important quantities \n",
    "a0pi0_short = predict_test['A_0'] / predict_test['pi0_short']\n",
    "a1pi1_short = predict_test['A_1'] / predict_test['pi1_short']\n",
    "a0pi0_true = predict_test['A_0'] / predict_test['pi0_true']\n",
    "a1pi1_true = predict_test['A_1'] / predict_test['pi1_true']\n",
    "\n",
    "diff_a0pi0 = a0pi0_true - a0pi0_short\n",
    "diff_a1pi1 = a1pi1_true - a1pi1_short\n",
    "\n",
    "diff_b0 = predict_test['b0_short'] - predict_test['b0_true']\n",
    "diff_b1 = predict_test['b1_short'] - predict_test['b1_true']\n"
   ],
   "id": "4de449d26a358cc",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.1 Compute the population quantity of mean potential outcome under treatment path $\\bar{A} = \\bar{1}$ (1)\n",
    "\n"
   ],
   "id": "613da43feb06d44d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T23:40:21.940919Z",
     "start_time": "2024-11-27T23:40:21.084629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean_Y_bar1 = np.mean(Y_bar1)\n",
    "display(Math(r\"E[Y^{{\\bar{{1}}}}] = {:.4f}\".format(mean_Y_bar1)))"
   ],
   "id": "bbfb52425a2a9e98",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Math object>"
      ],
      "text/latex": "$\\displaystyle E[Y^{\\bar{1}}] = 1.5196$"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2 Compute the population AIPW $\\psi$ based on (8)\n",
   "id": "84054c5225bd9719"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T23:40:24.833605Z",
     "start_time": "2024-11-27T23:40:24.709209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate psi_true\n",
    "psi_true = np.mean(predict_test['b0_true'] - a0pi0_true * predict_test['b0_true']\n",
    "            - a0pi0_true * a1pi1_true * predict_test['b1_true']\n",
    "            + a0pi0_true * predict_test['b1_true']\n",
    "            + a0pi0_true * a1pi1_true * predict_test['Y'])\n",
    "\n",
    "display(Math(r\"\\psi = {:.4f}\".format(psi_true)))\n"
   ],
   "id": "e6bf3e83b6511452",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Math object>"
      ],
      "text/latex": "$\\displaystyle \\psi = 1.5203$"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3 Compute the incorrect population AIPW $\\psi^*$ based on (11)\n",
   "id": "c5979786d51d582"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T23:40:28.375464Z",
     "start_time": "2024-11-27T23:40:28.237648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate psi_short\n",
    "psi_short = np.mean(predict_test['b0_short'] - a0pi0_short * predict_test['b0_short']\n",
    "            - a0pi0_short * a1pi1_short * predict_test['b1_short']\n",
    "            + a0pi0_short * predict_test['b1_short']\n",
    "            + a0pi0_short * a1pi1_short * predict_test['Y'])\n",
    "\n",
    "display(Math(r\"\\psi^* = {:.4f}\".format(psi_short)))\n"
   ],
   "id": "babe4841da895629",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Math object>"
      ],
      "text/latex": "$\\displaystyle \\psi^* = 1.9426$"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.4 Compute their difference $\\psi^*-\\psi$ as listed (12)\n",
   "id": "2becbc1d04381934"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T23:40:31.637161Z",
     "start_time": "2024-11-27T23:40:31.630484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "diff_psi = psi_short - psi_true\n",
    "display(Math(r\"\\psi^* - \\psi = {:.4f}\".format(diff_psi)))\n"
   ],
   "id": "a3ea77af331a5d07",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Math object>"
      ],
      "text/latex": "$\\displaystyle \\psi^* - \\psi = 0.4223$"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.5 Compute the basic ovb based on equation (13)\n",
   "id": "c584bd8278635cc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T23:40:38.210825Z",
     "start_time": "2024-11-27T23:40:38.114776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ovb_basic = np.mean(diff_b0 * diff_a0pi0 + a0pi0_short * diff_b1 * diff_a1pi1)\n",
    "print(f\"Basic OVB Formula = {ovb_basic:.4f}\")"
   ],
   "id": "ec8c9a0bf94a9d18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic OVB Formula = 0.4235\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.6 Compute updated ovb based on equation (26)",
   "id": "e9c5678aaeeba68b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T23:40:42.850155Z",
     "start_time": "2024-11-27T23:40:42.736456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "T1 = np.mean((predict_test['b0_short']- predict_test['ite_b1b0_short_true']) * diff_a0pi0)\n",
    "T2 = np.mean((predict_test['ite_b1b0_short_true'] - predict_test['b0_true']) * diff_a0pi0)\n",
    "T3 = np.mean(a0pi0_short * diff_b1 * diff_a1pi1)\n",
    "\n",
    "sum_T1_T2_T3 = T1 + T2 + T3\n",
    "\n",
    "print(f\"T1 + T2 + T3 = {sum_T1_T2_T3:.4f}\")"
   ],
   "id": "1c4ee9a9257e276f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 + T2 + T3 = 0.4235\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.7 Compute the ovb bound based on (14) together with (18) (19) (20)",
   "id": "d1c45eef99d7a2df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T23:40:51.459361Z",
     "start_time": "2024-11-27T23:40:51.263968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "T11_square = np.mean((predict_test['b0_short']- predict_test['ite_b1b0_short_true']) ** 2)\n",
    "T12_square = np.mean(diff_a0pi0 ** 2)\n",
    "T21_square = np.mean((predict_test['ite_b1b0_short_true'] - predict_test['b0_true']) ** 2)\n",
    "T21_square_prime = np.mean(diff_b1 ** 2)\n",
    "T22_square = np.mean(diff_a0pi0 ** 2)\n",
    "T31_square = np.mean(a0pi0_short * (diff_b1 ** 2))\n",
    "T32_square = np.mean(a0pi0_short * (diff_a1pi1 ** 2))\n",
    "\n",
    "T1_square_ub = T11_square * T12_square\n",
    "T2_square_ub = T21_square * T22_square\n",
    "T2_square_prime_ub = T21_square_prime * T22_square\n",
    "T3_square_ub = T31_square * T32_square\n",
    "print(T1_square_ub, T2_square_prime_ub, T3_square_ub)\n",
    "\n",
    "T1_ub = np.sqrt(T1_square_ub)\n",
    "T2_ub = np.sqrt(T2_square_ub)\n",
    "T2_prime_ub = np.sqrt(T2_square_prime_ub)\n",
    "T3_ub = np.sqrt(T3_square_ub)\n",
    "\n",
    "ovb_prime_ub = T1_ub + T2_prime_ub + T3_ub\n",
    "display(Math(r\"|\\psi^* - \\psi| \\le |T_1| + |T_2| + |T_3| \\le {:.4f}\".format(ovb_prime_ub)))\n"
   ],
   "id": "6f4d19e0a0bf3eb6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07774571209550799 0.2944008302357661 0.04216876170865968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Math object>"
      ],
      "text/latex": "$\\displaystyle |\\psi^* - \\psi| \\le |T_1| + |T_2| + |T_3| \\le 1.0268$"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.8 Compute the ovb bound based on (14), (18) (19) (20), and corollary 1.",
   "id": "fd8b1c60b1db14b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T23:41:02.374038Z",
     "start_time": "2024-11-27T23:41:01.752401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "C1b1_square = (np.mean((predict_test['b0_short'] - predict_test['ite_b1b0_short_true']) ** 2) / \n",
    "               np.mean((predict_test['b1_short'] - predict_test['ite_b1b0_short_true']) ** 2))\n",
    "S1_square = np.mean((predict_test['b1_short'] - predict_test['ite_b1b0_short_true']) ** 2) * np.mean(a0pi0_short ** 2)\n",
    "Ca0_square = np.mean(diff_a0pi0 ** 2) / np.mean(a0pi0_short ** 2)\n",
    "\n",
    "C1b1_square_S1_square_Ca0_square = C1b1_square * S1_square * Ca0_square\n",
    "\n",
    "Cy_square = np.mean(diff_b1 ** 2) / np.mean((predict_test['Y'] - predict_test['b1_short']) ** 2)\n",
    "S2_square = np.mean((predict_test['Y'] - predict_test['b1_short']) ** 2) * np.mean(a0pi0_short ** 2)\n",
    "\n",
    "Cy_square_S2_square_Ca0_square =  Cy_square * S2_square * Ca0_square\n",
    "\n",
    "C_tilde_y_square = np.mean(a0pi0_short * (diff_b1 ** 2)) / np.mean(a0pi0_short * ((predict_test['Y'] - predict_test['b1_short']) ** 2)) \n",
    "S3_square = np.mean(a0pi0_short * ((predict_test['Y'] - predict_test['b1_short']) ** 2)) * np.mean(a0pi0_short * (a1pi1_short ** 2))\n",
    "C_tilde_a1_square = np.mean(a0pi0_short * (diff_a1pi1 ** 2)) / np.mean(a0pi0_short * (a1pi1_short ** 2))\n",
    "\n",
    "C_tilde_y_square_S3_square_C_tilde_a1_square = C_tilde_y_square * S3_square * C_tilde_a1_square\n",
    "\n",
    "display(Math(r\"C_{{b_1^*}}^2 S_1^2 C_{{A_0}}^2 = {:.4f}\".format(C1b1_square_S1_square_Ca0_square)))\n",
    "display(Math(r\"C_{{Y}}^2 S_2^2 C_{{A_0}}^2 = {:.4f}\".format(Cy_square_S2_square_Ca0_square)))\n",
    "display(Math(r\"C_{{\\tilde{{Y}}}}^2 S_3^2 C_{{\\tilde{{A}}_1}}^2 = {:.4f}\".format(C_tilde_y_square_S3_square_C_tilde_a1_square)))\n",
    "\n"
   ],
   "id": "d03f9db3637d387d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Math object>"
      ],
      "text/latex": "$\\displaystyle C_{b_1^*}^2 S_1^2 C_{A_0}^2 = 0.0777$"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Math object>"
      ],
      "text/latex": "$\\displaystyle C_{Y}^2 S_2^2 C_{A_0}^2 = 0.2944$"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Math object>"
      ],
      "text/latex": "$\\displaystyle C_{\\tilde{Y}}^2 S_3^2 C_{\\tilde{A}_1}^2 = 0.0422$"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.9 Summary table\n",
   "id": "ee182fb8237ce90d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T23:41:10.089308Z",
     "start_time": "2024-11-27T23:41:10.081515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Define the quantities to include in the summary table\n",
    "summary_data = {\n",
    "    \"Row Name\": [\n",
    "        r\"$\\mathbb{E}[Y^{\\bar{1}}]$\",\n",
    "        r\"$\\psi$\",\n",
    "        r\"$\\psi^*$\",\n",
    "        r\"$\\psi^* - \\psi$\",\n",
    "        r\"Basic OVB\",\n",
    "        r\"$T_1 + T_2 + T_3$\",\n",
    "        r\"$|\\psi^* - \\psi| \\leq |T_1| + |T_2| + |T_3| \\leq (C_{{b_1^*}}^2 S_1^2 C_{{A_0}}^2)^{1/2} + (C_{{Y}}^2 S_2^2 C_{{A_0}}^2)^{1/2} + (C_{{\\tilde{{Y}}}}^2 S_3^2 C_{{\\tilde{{A}}_1}}^2)^{1/2}$\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        mean_Y_bar1,  \n",
    "        psi_true,  \n",
    "        psi_short,  \n",
    "        diff_psi,  \n",
    "        ovb_basic,  \n",
    "        sum_T1_T2_T3,  \n",
    "        ovb_prime_ub  \n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the table header with spacing\n",
    "markdown_table = \"| Row Name                              | Value     |\\n\"\n",
    "markdown_table += \"|---------------------------------------|-----------|\\n\"\n",
    "\n",
    "# Add each row to the table with better spacing\n",
    "for name, value in zip(summary_data[\"Row Name\"], summary_data[\"Value\"]):\n",
    "    markdown_table += f\"| {name}                                | {value:.6f} |\\n\"\n",
    "\n",
    "# Display the formatted table\n",
    "display(Markdown(markdown_table))\n"
   ],
   "id": "efbc67de9c428785",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "| Row Name                              | Value     |\n|---------------------------------------|-----------|\n| $\\mathbb{E}[Y^{\\bar{1}}]$                                | 1.519628 |\n| $\\psi$                                | 1.520277 |\n| $\\psi^*$                                | 1.942568 |\n| $\\psi^* - \\psi$                                | 0.422291 |\n| Basic OVB                                | 0.423459 |\n| $T_1 + T_2 + T_3$                                | 0.423459 |\n| $|\\psi^* - \\psi| \\leq |T_1| + |T_2| + |T_3| \\leq (C_{{b_1^*}}^2 S_1^2 C_{{A_0}}^2)^{1/2} + (C_{{Y}}^2 S_2^2 C_{{A_0}}^2)^{1/2} + (C_{{\\tilde{{Y}}}}^2 S_3^2 C_{{\\tilde{{A}}_1}}^2)^{1/2}$                                | 1.026767 |\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
